{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe94e6da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    }
   ],
   "source": [
    "print('ok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02de0827",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\ASUS\\\\Desktop\\\\Medical_Chatbot\\\\Medical-Chatbot-Langchain-Pinecone-Flask-AWS-LLM\\\\research'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b2cfc3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "os.chdir('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f19dbd18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\ASUS\\\\Desktop\\\\Medical_Chatbot\\\\Medical-Chatbot-Langchain-Pinecone-Flask-AWS-LLM'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8ec5194",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader,DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "93949bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load PDF files from a specified directory and extract the text content\n",
    "def load_pdf_files(data):\n",
    "    loader=DirectoryLoader(data,glob=\"**/*.pdf\",loader_cls=PyPDFLoader)\n",
    "    documents=loader.load()\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2d3812cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents loaded: 637\n"
     ]
    }
   ],
   "source": [
    "extracted_data=load_pdf_files('data')\n",
    "print(f'Number of documents loaded: {len(extracted_data)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "66ae2df0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'producer': 'PDFlib+PDI 5.0.0 (SunOS)', 'creator': 'PyPDF', 'creationdate': '2004-12-18T17:00:02-05:00', 'moddate': '2004-12-18T16:15:31-06:00', 'source': 'data\\\\Medical_book.pdf', 'total_pages': 637, 'page': 0, 'page_label': '1'}, page_content='')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extracted_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "26bd682d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from langchain.schema import Document\n",
    "\n",
    "def filter_to_minimal_docs(docs: List[Document]) -> List[Document]:\n",
    "    \"\"\"\n",
    "    Given a list of Document objects, return a new list of Document objects\n",
    "    containing only 'source' in metadata and the original page_content.\n",
    "    \"\"\"\n",
    "    minimal_docs: List[Document] = []\n",
    "    for doc in docs:\n",
    "        src = doc.metadata.get(\"source\")\n",
    "        minimal_docs.append(\n",
    "            Document(\n",
    "                page_content=doc.page_content,\n",
    "                metadata={\"source\": src}\n",
    "            )\n",
    "        )\n",
    "    return minimal_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fcaf085b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'source': 'data\\\\Medical_book.pdf'}, page_content='')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minimal_docs=filter_to_minimal_docs(extracted_data)\n",
    "minimal_docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5604abdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the documents into smaller chunks\n",
    "def text_split(minimal_docs):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=500,\n",
    "        chunk_overlap=100,\n",
    "    )\n",
    "    texts_chunk = text_splitter.split_documents(minimal_docs)\n",
    "    return texts_chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7e7dd33d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of chunks: 6600\n"
     ]
    }
   ],
   "source": [
    "texts_chunk = text_split(minimal_docs)\n",
    "print(f\"Number of chunks: {len(texts_chunk)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bcafd029",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_9944\\30168171.py:8: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = HuggingFaceEmbeddings(\n",
      "c:\\Users\\ASUS\\anaconda3\\envs\\medicalbot\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "def download_embeddings():\n",
    "    \"\"\"\n",
    "    Download and return the HuggingFace embeddings model.\n",
    "    \"\"\"\n",
    "    model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "    embeddings = HuggingFaceEmbeddings(\n",
    "        model_name=model_name\n",
    "    )\n",
    "    return embeddings\n",
    "\n",
    "embedding = download_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bd9d5c7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HuggingFaceEmbeddings(client=SentenceTransformer(\n",
       "  (0): Transformer({'max_seq_length': 256, 'do_lower_case': False}) with Transformer model: BertModel \n",
       "  (1): Pooling({'word_embedding_dimension': 384, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
       "  (2): Normalize()\n",
       "), model_name='sentence-transformers/all-MiniLM-L6-v2', cache_folder=None, model_kwargs={}, encode_kwargs={}, multi_process=False, show_progress=False)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4e88f660",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.03447727486491203,\n",
       " 0.03102317824959755,\n",
       " 0.006734970025718212,\n",
       " 0.026108985766768456,\n",
       " -0.03936202451586723,\n",
       " -0.16030244529247284,\n",
       " 0.06692401319742203,\n",
       " -0.006441489793360233,\n",
       " -0.0474504791200161,\n",
       " 0.014758856035768986,\n",
       " 0.07087527960538864,\n",
       " 0.05552763119339943,\n",
       " 0.019193334504961967,\n",
       " -0.026251312345266342,\n",
       " -0.01010954286903143,\n",
       " -0.02694045566022396,\n",
       " 0.022307461127638817,\n",
       " -0.022226648405194283,\n",
       " -0.14969263970851898,\n",
       " -0.017493007704615593,\n",
       " 0.00767625542357564,\n",
       " 0.05435224249958992,\n",
       " 0.0032543970737606287,\n",
       " 0.031725890934467316,\n",
       " -0.0846213847398758,\n",
       " -0.02940601296722889,\n",
       " 0.05159561336040497,\n",
       " 0.04812406003475189,\n",
       " -0.0033148222137242556,\n",
       " -0.058279167860746384,\n",
       " 0.04196927323937416,\n",
       " 0.022210685536265373,\n",
       " 0.1281888335943222,\n",
       " -0.022338971495628357,\n",
       " -0.011656315997242928,\n",
       " 0.06292839348316193,\n",
       " -0.032876335084438324,\n",
       " -0.09122604131698608,\n",
       " -0.031175347045063972,\n",
       " 0.0526994913816452,\n",
       " 0.04703482985496521,\n",
       " -0.08420311659574509,\n",
       " -0.030056199058890343,\n",
       " -0.02074483036994934,\n",
       " 0.009517835453152657,\n",
       " -0.0037217906210571527,\n",
       " 0.007343285251408815,\n",
       " 0.03932438790798187,\n",
       " 0.0932740643620491,\n",
       " -0.003788596484810114,\n",
       " -0.052742067724466324,\n",
       " -0.05805816128849983,\n",
       " -0.006864361464977264,\n",
       " 0.005283191800117493,\n",
       " 0.0828929990530014,\n",
       " 0.019362755119800568,\n",
       " 0.0062844837084412575,\n",
       " -0.010330787859857082,\n",
       " 0.009032378904521465,\n",
       " -0.037683695554733276,\n",
       " -0.04520607739686966,\n",
       " 0.024016305804252625,\n",
       " -0.006944137159734964,\n",
       " 0.013491630554199219,\n",
       " 0.10005494207143784,\n",
       " -0.07168391346931458,\n",
       " -0.021695120260119438,\n",
       " 0.031618405133485794,\n",
       " -0.051634665578603745,\n",
       " -0.08224772661924362,\n",
       " -0.06569333374500275,\n",
       " -0.00989533495157957,\n",
       " 0.005816374905407429,\n",
       " 0.07355456054210663,\n",
       " -0.034050311893224716,\n",
       " 0.0248861201107502,\n",
       " 0.014488042332231998,\n",
       " 0.02645738422870636,\n",
       " 0.009656722657382488,\n",
       " 0.0302172489464283,\n",
       " 0.05280393362045288,\n",
       " -0.07535984367132187,\n",
       " 0.009897145442664623,\n",
       " 0.029836809262633324,\n",
       " 0.01755557768046856,\n",
       " 0.023091984912753105,\n",
       " 0.001933806692250073,\n",
       " 0.0014002545503899455,\n",
       " -0.04717595875263214,\n",
       " -0.011194315738976002,\n",
       " -0.11420144140720367,\n",
       " -0.019811924546957016,\n",
       " 0.040266189724206924,\n",
       " 0.0021929906215518713,\n",
       " -0.07979220896959305,\n",
       " -0.02538231760263443,\n",
       " 0.09448299556970596,\n",
       " -0.02898104302585125,\n",
       " -0.14500252902507782,\n",
       " 0.23097744584083557,\n",
       " 0.027731187641620636,\n",
       " 0.03211146965622902,\n",
       " 0.03106505796313286,\n",
       " 0.04283284768462181,\n",
       " 0.06423777341842651,\n",
       " 0.03216316178441048,\n",
       " -0.004876770544797182,\n",
       " 0.055699463933706284,\n",
       " -0.03753238171339035,\n",
       " -0.02150554023683071,\n",
       " -0.028342634439468384,\n",
       " -0.028846951201558113,\n",
       " 0.0383530892431736,\n",
       " -0.017468664795160294,\n",
       " 0.052485305815935135,\n",
       " -0.07487601786851883,\n",
       " -0.03125976398587227,\n",
       " 0.021841565147042274,\n",
       " -0.03989570587873459,\n",
       " -0.008587091229856014,\n",
       " 0.026956576853990555,\n",
       " -0.04849553853273392,\n",
       " 0.011469882912933826,\n",
       " 0.02961820363998413,\n",
       " -0.02057218924164772,\n",
       " 0.013103843666613102,\n",
       " 0.028833510354161263,\n",
       " -3.1941990848222185e-33,\n",
       " 0.06478213518857956,\n",
       " -0.018130183219909668,\n",
       " 0.051789961755275726,\n",
       " 0.12198275327682495,\n",
       " 0.028780106455087662,\n",
       " 0.008721951395273209,\n",
       " -0.07052119821310043,\n",
       " -0.016907278448343277,\n",
       " 0.04073973000049591,\n",
       " 0.042116157710552216,\n",
       " 0.025447236374020576,\n",
       " 0.03574628755450249,\n",
       " -0.04914471507072449,\n",
       " 0.0021290204022079706,\n",
       " -0.015546582639217377,\n",
       " 0.050730545073747635,\n",
       " -0.0481853261590004,\n",
       " 0.03588061034679413,\n",
       " -0.0040670474991202354,\n",
       " 0.10172472149133682,\n",
       " -0.05597002059221268,\n",
       " -0.010681048966944218,\n",
       " 0.01123578567057848,\n",
       " 0.09068653732538223,\n",
       " 0.004234451334923506,\n",
       " 0.035138655453920364,\n",
       " -0.009702847339212894,\n",
       " -0.09386517852544785,\n",
       " 0.0928555428981781,\n",
       " 0.008004927076399326,\n",
       " -0.007705425377935171,\n",
       " -0.05208674445748329,\n",
       " -0.012587991543114185,\n",
       " 0.0032669377978891134,\n",
       " 0.006013509817421436,\n",
       " 0.007581559009850025,\n",
       " 0.01051718182861805,\n",
       " -0.08634556829929352,\n",
       " -0.06987880170345306,\n",
       " -0.0025338928680866957,\n",
       " -0.09097658842802048,\n",
       " 0.04688733071088791,\n",
       " 0.052076540887355804,\n",
       " 0.007193844299763441,\n",
       " 0.010903622955083847,\n",
       " -0.0052295587956905365,\n",
       " 0.013937311246991158,\n",
       " 0.021968349814414978,\n",
       " 0.03420866280794144,\n",
       " 0.060224682092666626,\n",
       " 0.00011665470083244145,\n",
       " 0.014731976203620434,\n",
       " -0.07008926570415497,\n",
       " 0.028499048203229904,\n",
       " -0.02760172076523304,\n",
       " 0.010768445208668709,\n",
       " 0.034830961376428604,\n",
       " -0.02248787134885788,\n",
       " 0.009769017808139324,\n",
       " 0.07722785323858261,\n",
       " 0.021588314324617386,\n",
       " 0.11495620757341385,\n",
       " -0.0680011734366417,\n",
       " 0.02376098558306694,\n",
       " -0.0159839428961277,\n",
       " -0.0178269911557436,\n",
       " 0.06439495831727982,\n",
       " 0.032025739550590515,\n",
       " 0.05027025192975998,\n",
       " -0.005913770757615566,\n",
       " -0.03370805084705353,\n",
       " 0.017840256914496422,\n",
       " 0.016573317348957062,\n",
       " 0.06329657882452011,\n",
       " 0.03467721864581108,\n",
       " 0.046473488211631775,\n",
       " 0.09790610522031784,\n",
       " -0.00663550291210413,\n",
       " 0.02520712837576866,\n",
       " -0.07798824459314346,\n",
       " 0.0169264767318964,\n",
       " -0.000945797364693135,\n",
       " 0.022471921518445015,\n",
       " -0.038253191858530045,\n",
       " 0.09570474177598953,\n",
       " -0.005350803025066853,\n",
       " 0.010469110682606697,\n",
       " -0.11524055153131485,\n",
       " -0.013262521475553513,\n",
       " -0.010709455236792564,\n",
       " -0.08311725407838821,\n",
       " 0.07327353954315186,\n",
       " 0.04939225688576698,\n",
       " -0.008994322270154953,\n",
       " -0.09584552049636841,\n",
       " 3.3661485617505796e-33,\n",
       " 0.12493184208869934,\n",
       " 0.01934972032904625,\n",
       " -0.05822571739554405,\n",
       " -0.03598826378583908,\n",
       " -0.05074676498770714,\n",
       " -0.04566238448023796,\n",
       " -0.08260336518287659,\n",
       " 0.1481948047876358,\n",
       " -0.08842118829488754,\n",
       " 0.06027443706989288,\n",
       " 0.05103015899658203,\n",
       " 0.01030314713716507,\n",
       " 0.14121422171592712,\n",
       " 0.03081384487450123,\n",
       " 0.061033159494400024,\n",
       " -0.052851270884275436,\n",
       " 0.1366489678621292,\n",
       " 0.00918989721685648,\n",
       " -0.01732518896460533,\n",
       " -0.012848555110394955,\n",
       " -0.007995282299816608,\n",
       " -0.0509800985455513,\n",
       " -0.05235064774751663,\n",
       " 0.007593012880533934,\n",
       " -0.015166307799518108,\n",
       " 0.01696030981838703,\n",
       " 0.021270520985126495,\n",
       " 0.020558107644319534,\n",
       " -0.12002813816070557,\n",
       " 0.014461833983659744,\n",
       " 0.02675991877913475,\n",
       " 0.025330696254968643,\n",
       " -0.0427546352148056,\n",
       " 0.006768387276679277,\n",
       " -0.01445858459919691,\n",
       " 0.04526195675134659,\n",
       " -0.09147648513317108,\n",
       " -0.019439145922660828,\n",
       " -0.017833467572927475,\n",
       " -0.05491018295288086,\n",
       " -0.052641112357378006,\n",
       " -0.010459048673510551,\n",
       " -0.052016086876392365,\n",
       " 0.020891955122351646,\n",
       " -0.07997036725282669,\n",
       " -0.012111340649425983,\n",
       " -0.05773142725229263,\n",
       " 0.023178234696388245,\n",
       " -0.008031732402741909,\n",
       " -0.02598930336534977,\n",
       " -0.07995671033859253,\n",
       " -0.020728832110762596,\n",
       " 0.048817697912454605,\n",
       " -0.020389137789607048,\n",
       " -0.04917657747864723,\n",
       " 0.014159622602164745,\n",
       " -0.06362202018499374,\n",
       " -0.007807393092662096,\n",
       " 0.01643155701458454,\n",
       " -0.0256824791431427,\n",
       " 0.013381040655076504,\n",
       " 0.026248741894960403,\n",
       " 0.009978413581848145,\n",
       " 0.06322886794805527,\n",
       " 0.002672201255336404,\n",
       " -0.006582767236977816,\n",
       " 0.01663188263773918,\n",
       " 0.03236646577715874,\n",
       " 0.03794245794415474,\n",
       " -0.036376070231199265,\n",
       " -0.006910930387675762,\n",
       " 0.0001596928050275892,\n",
       " -0.0016335808904841542,\n",
       " -0.02727821283042431,\n",
       " -0.02803807333111763,\n",
       " 0.049681417644023895,\n",
       " -0.028867173939943314,\n",
       " -0.0024180689360946417,\n",
       " 0.014774908311665058,\n",
       " 0.009764534421265125,\n",
       " 0.005797638092190027,\n",
       " 0.013486160896718502,\n",
       " 0.0055678957141935825,\n",
       " 0.03722710534930229,\n",
       " 0.007232527248561382,\n",
       " 0.04015626385807991,\n",
       " 0.08150326460599899,\n",
       " 0.07199167460203171,\n",
       " -0.013056126423180103,\n",
       " -0.0428820475935936,\n",
       " -0.01101123820990324,\n",
       " 0.004897820297628641,\n",
       " -0.009229730814695358,\n",
       " 0.035191506147384644,\n",
       " -0.05103502422571182,\n",
       " -1.571437557856825e-08,\n",
       " -0.08862441033124924,\n",
       " 0.02390925958752632,\n",
       " -0.01623876392841339,\n",
       " 0.031700510531663895,\n",
       " 0.027284247800707817,\n",
       " 0.05246882885694504,\n",
       " -0.047070957720279694,\n",
       " -0.058847445994615555,\n",
       " -0.06320822983980179,\n",
       " 0.04088849574327469,\n",
       " 0.04982800409197807,\n",
       " 0.10655171424150467,\n",
       " -0.07450230419635773,\n",
       " -0.012495421804487705,\n",
       " 0.01837071217596531,\n",
       " 0.03947412595152855,\n",
       " -0.024797886610031128,\n",
       " 0.014516262337565422,\n",
       " -0.03706921637058258,\n",
       " 0.02001572772860527,\n",
       " -4.85817035951186e-05,\n",
       " 0.00986657664179802,\n",
       " 0.024838753044605255,\n",
       " -0.05245814099907875,\n",
       " 0.029314178973436356,\n",
       " -0.08719190955162048,\n",
       " -0.01449968758970499,\n",
       " 0.026019077748060226,\n",
       " -0.01874636672437191,\n",
       " -0.07620512694120407,\n",
       " 0.03504333272576332,\n",
       " 0.10363949835300446,\n",
       " -0.028050510212779045,\n",
       " 0.012718182988464832,\n",
       " -0.07632549107074738,\n",
       " -0.01865232177078724,\n",
       " 0.02497672848403454,\n",
       " 0.0814453512430191,\n",
       " 0.06875883787870407,\n",
       " -0.0640566498041153,\n",
       " -0.08389385789632797,\n",
       " 0.06136231869459152,\n",
       " -0.033545564860105515,\n",
       " -0.10615336894989014,\n",
       " -0.040080588310956955,\n",
       " 0.032530225813388824,\n",
       " 0.07662483304738998,\n",
       " -0.0730162113904953,\n",
       " 0.00033755265758372843,\n",
       " -0.040871646255254745,\n",
       " -0.0757884755730629,\n",
       " 0.027527665719389915,\n",
       " 0.07462543249130249,\n",
       " 0.01771726831793785,\n",
       " 0.09121846407651901,\n",
       " 0.11022016406059265,\n",
       " 0.0005697731394320726,\n",
       " 0.05146336182951927,\n",
       " -0.014551310800015926,\n",
       " 0.03323203697800636,\n",
       " 0.023792240768671036,\n",
       " -0.02288980595767498,\n",
       " 0.038937538862228394,\n",
       " 0.030206844210624695]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector = embedding.embed_query(\"Hello world\")\n",
    "vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "940f5316",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vector length: 384\n"
     ]
    }
   ],
   "source": [
    "print(\"vector length:\", len(vector))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ecab4e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()\n",
    "PINECONE_API_KEY = os.getenv(\"PINECONE_API_KEY\")\n",
    "os.environ[\"PINECONE_API_KEY\"] = PINECONE_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b9c8cabb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone import Pinecone \n",
    "pinecone_api_key = PINECONE_API_KEY\n",
    "\n",
    "pc = Pinecone(api_key=pinecone_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c7497827",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pinecone.pinecone.Pinecone at 0x2386f6a3a00>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b5fe8521",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone import ServerlessSpec \n",
    "\n",
    "index_name = \"medical-chatbot\"\n",
    "\n",
    "if not pc.has_index(index_name):\n",
    "    pc.create_index(\n",
    "        name = index_name,\n",
    "        dimension=384,  # Dimension of the embeddings\n",
    "        metric= \"cosine\",  # Cosine similarity\n",
    "        spec=ServerlessSpec(cloud=\"aws\", region=\"us-east-1\")\n",
    "    )\n",
    "\n",
    "\n",
    "index = pc.Index(index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "33c47856",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_pinecone import PineconeVectorStore\n",
    "\n",
    "docsearch = PineconeVectorStore.from_documents(\n",
    "    documents=texts_chunk,\n",
    "    embedding=embedding,\n",
    "    index_name=index_name\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e4160a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Existing index \n",
    "\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "# Embed each chunk and upsert the embeddings into your Pinecone index.\n",
    "docsearch = PineconeVectorStore.from_existing_index(\n",
    "    index_name=index_name,\n",
    "    embedding=embedding\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3d9916e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = docsearch.as_retriever(search_type=\"similarity\", search_kwargs={\"k\":5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "99829c4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='35405993-1f0e-4639-9ba4-3ad76fdd5471', metadata={'source': 'data\\\\Medical_book.pdf'}, page_content='Journal of Urology (Mar. 1998): 935-940.\\nNancy J. Nordenson\\nAcid reflux see Heartburn\\nAcidosis see Respiratory acidosis; Renal\\ntubular acidosis; Metabolic acidosis\\nAcne\\nDefinition\\nAcne is a common skin disease characterized by\\npimples on the face, chest, and back. It occurs when the\\npores of the skin become clogged with oil, dead skin\\ncells, and bacteria.\\nDescription\\nAcne vulgaris, the medical term for common acne, is\\nthe most common skin disease. It affects nearly 17 million'),\n",
       " Document(id='dcd5bd99-0baf-4f1e-9839-2b06be741aa8', metadata={'source': 'data\\\\Medical_book.pdf'}, page_content='creams containing benzoyl peroxide or tretinoin may be\\nused to clear up mild to moderately severe acne.\\nIsotretinoin (Accutane) is prescribed only for very\\nsevere, disfiguring acne.\\nAcne is a skin condition that occurs when pores or\\nhair follicles become blocked. This allows a waxy\\nmaterial, sebum, to collect inside the pores or follicles.\\nNormally, sebum flows out onto the skin and hair to\\nform a protective coating, but when it cannot get out,'),\n",
       " Document(id='9832f47d-096e-4f1e-a75c-666c30b070d7', metadata={'source': 'data\\\\Medical_book.pdf'}, page_content='noninflammatory acne consists of the two types of come-\\ndones, whiteheads and blackheads.\\nModerate and severe inflammatory types of acne\\nresult after the plugged follicle is invaded by Propioni-\\nbacterium acnes , a bacteria that normally lives on the\\nskin. A pimple forms when the damaged follicle weakens\\nand bursts open, releasing sebum, bacteria, and skin and\\nwhite blood cells into the surrounding tissues. Inflamed\\npimples near the skin’s surface are called papules; when'),\n",
       " Document(id='095f3d53-a850-4abc-802a-597454bb892a', metadata={'source': 'data\\\\Medical_book.pdf'}, page_content='effective treatment is topical tretinoin along with a topical\\nGALE ENCYCLOPEDIA OF MEDICINE 2 25\\nAcne\\nAcne vulgaris affecting a woman’s face. Acne is the general\\nname given to a skin disorder in which the sebaceous\\nglands become inflamed. (Photograph by Biophoto Associ-\\nates, Photo Researchers, Inc. Reproduced by permission.)\\nGEM - 0001 to 0432 - A  10/22/03 1:41 PM  Page 25'),\n",
       " Document(id='95927aa6-014e-407d-af02-9de9900c8323', metadata={'source': 'data\\\\Medical_book.pdf'}, page_content='48-52.\\nChristiano, Donna. “Acne Treatment Meant for Grown- Ups.”\\nAmerican Health (Oct. 1994): 23-4.\\n“Clearly Better New Treatments Help Adult Acne.”Prevention\\nMagazine, Aug. 1997, 50-51.\\nLeyden, James J. “Therapy For Acne Vulgaris.”New England\\nJournal of Medicine 17 (Apr. 1997): 1156-1162.\\nNguyen, Quan H., Y . Alyssa Kim, and Robert A. Schwartz.\\n“Management of Acne Vulgaris.”American Family Physi-\\ncian (July 1994): 89-96.\\n“Pimple Control Pill?” Prevention Magazine, May 1997, 132.\\nORGANIZATIONS')]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieved_docs = retriever.invoke(\"What is Acne?\")\n",
    "retrieved_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0e5fcab5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI key loaded: True\n",
      "Pinecone key loaded: True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()  # This reads your .env file\n",
    "\n",
    "# Test if keys are loaded\n",
    "print(\"OpenAI key loaded:\", bool(os.getenv(\"OPENAI_API_KEY\")))\n",
    "print(\"Pinecone key loaded:\", bool(os.getenv(\"PINECONE_API_KEY\")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6be55ef9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your OpenAI API key is: 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\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()  # Loads your .env file\n",
    "\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "print(\"Your OpenAI API key is:\", api_key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "1b5e7e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "chatModel = ChatOpenAI(model=\"gpt-3.5-turbo\", openai_api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "278f3cda",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both GOOGLE_API_KEY and GEMINI_API_KEY are set. Using GOOGLE_API_KEY.\n"
     ]
    }
   ],
   "source": [
    "from langchain.llms.base import LLM\n",
    "from typing import Optional, List\n",
    "from google import genai\n",
    "from pydantic import BaseModel, Field\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "client = genai.Client(api_key=os.getenv(\"GEMINI_API_KEY\"))\n",
    "\n",
    "class GeminiLLM(LLM, BaseModel):\n",
    "    model: str = Field(default=\"gemini-2.5-flash\")  # Pydantic field\n",
    "\n",
    "    def _call(self, prompt: str, stop: Optional[List[str]] = None) -> str:\n",
    "        # Ensure prompt is a string\n",
    "        if isinstance(prompt, dict) and \"input\" in prompt:\n",
    "            prompt = prompt[\"input\"]\n",
    "        if not prompt:\n",
    "            prompt = \" \"\n",
    "        response = client.models.generate_content(model=self.model, contents=prompt)\n",
    "        return response.text\n",
    "\n",
    "    @property\n",
    "    def _identifying_params(self):\n",
    "        return {\"model\": self.model}\n",
    "\n",
    "    @property\n",
    "    def _llm_type(self):\n",
    "        return \"gemini\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "7bac7152",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acromegaly is a disorder where the pituitary gland releases an abnormal chemical, causing increased growth in bone and soft tissue after bone growth stops. Gigantism is the same disorder occurring in children, resulting in exceptional growth of long bones and unusual height.\n",
      "The specific treatments are not detailed in the provided context, but treatment is crucial for living a normal lifespan.\n",
      "Yes, you should consult a doctor as soon as possible due to the serious health risks if left untreated.\n"
     ]
    }
   ],
   "source": [
    "chatModel = GeminiLLM()\n",
    "question_answer_chain = create_stuff_documents_chain(chatModel, prompt)\n",
    "rag_chain = create_retrieval_chain(retriever, question_answer_chain)\n",
    "\n",
    "response = rag_chain.invoke({\"input\": \"what is Acromegaly and gigantism?\"})\n",
    "print(response[\"answer\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ee5a04ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "8750c089",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = (\n",
    "    \"You are a knowledgeable medical assistant tasked with answering patient questions. \"\n",
    "    \"Use the following retrieved context to provide accurate and concise answers. \"\n",
    "    \"For each question, include:\\n\"\n",
    "    \"1. A brief description of the disease (about 2 lines).\\n\"\n",
    "    \"2. Common treatments or management options (1-2 lines).\\n\"\n",
    "    \"3. Advice on whether the person should consult a doctor (1 line).\\n\"\n",
    "    \"Keep the total answer around 5 lines. \"\n",
    "    \"If the answer is not in the context, say you don't know.\\n\\n\"\n",
    "    \"{context}\"\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "bfb8cb66",
   "metadata": {},
   "outputs": [],
   "source": [
    "question_answer_chain = create_stuff_documents_chain(chatModel, prompt)\n",
    "rag_chain = create_retrieval_chain(retriever, question_answer_chain)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "medicalbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
